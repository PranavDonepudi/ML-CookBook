{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction - Hands-On Exercise\n",
    "\n",
    "**Based on: DataCamp Supervised Learning Chapter 1**\n",
    "\n",
    "This notebook walks you through applying classification concepts step-by-step.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By completing this notebook, you will:\n",
    "1. Apply train-test split properly\n",
    "2. Train multiple classification models\n",
    "3. Evaluate using multiple metrics\n",
    "4. Compare model performance\n",
    "5. Make predictions on new data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "**Task**: Import all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Data\n",
    "\n",
    "**Task**: Create a synthetic churn dataset for practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create synthetic churn data\n",
    "X, y = make_classification(\n",
    "    n_samples=2000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.75, 0.25],  # 25% churn rate\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "feature_names = [\n",
    "    'account_length', 'international_plan', 'voice_mail_plan',\n",
    "    'num_voice_messages', 'total_day_minutes', 'total_day_calls',\n",
    "    'total_eve_minutes', 'total_night_minutes', 'total_intl_calls',\n",
    "    'customer_service_calls'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['churn'] = y\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploratory Data Analysis\n",
    "\n",
    "**Task**: Understand the dataset before modeling\n",
    "\n",
    "### 3.1 Check class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Calculate the percentage of churned vs non-churned customers\n",
    "churn_counts = df['churn'].value_counts()\n",
    "churn_pct = df['churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Churn Distribution:\")\n",
    "print(f\"No Churn (0): {churn_counts[0]} ({churn_pct[0]:.1f}%)\")\n",
    "print(f\"Churn (1): {churn_counts[1]} ({churn_pct[1]:.1f}%)\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 5))\n",
    "churn_counts.plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Churn Distribution')\n",
    "plt.xlabel('Churn (0=No, 1=Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# QUESTION: Is this dataset balanced or imbalanced? Why does it matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Display summary statistics for all features\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data\n",
    "\n",
    "**Concept from DataCamp**: Always split data before training!\n",
    "\n",
    "### 4.1 Separate features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Separate X (features) and y (target)\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train-Test Split\n",
    "\n",
    "**Key Parameters**:\n",
    "- `test_size`: Proportion for test set (typically 0.2 or 0.3)\n",
    "- `random_state`: For reproducibility\n",
    "- `stratify`: Maintains class distribution in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Split the data with test_size=0.2, random_state=42, stratify=y\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify stratification worked\n",
    "print(f\"\\nTraining set churn rate: {y_train.mean()*100:.1f}%\")\n",
    "print(f\"Test set churn rate: {y_test.mean()*100:.1f}%\")\n",
    "\n",
    "# QUESTION: Why is stratification important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Scaling\n",
    "\n",
    "**Why scale?** Some algorithms (Logistic Regression, KNN) are sensitive to feature magnitudes.\n",
    "\n",
    "**Important**: Fit scaler on training data, then transform both train and test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Create StandardScaler and fit_transform training data, transform test data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"âœ… Features scaled\")\n",
    "print(f\"\\nOriginal feature ranges:\")\n",
    "print(X_train.describe().loc[['min', 'max']].round(2))\n",
    "print(f\"\\nScaled feature means (should be ~0):\")\n",
    "print(pd.DataFrame(X_train_scaled, columns=X.columns).mean().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Models\n",
    "\n",
    "**Task**: Train 4 different classification models\n",
    "\n",
    "### 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Train Logistic Regression on SCALED data\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Train KNN with n_neighbors=5 on SCALED data\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"KNN Accuracy: {accuracy_knn:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Train Decision Tree with max_depth=5 on UNSCALED data (trees don't need scaling)\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "y_pred_proba_dt = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_dt:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "# Train Random Forest with n_estimators=100, max_depth=5\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Models\n",
    "\n",
    "**Concept**: Accuracy alone is not enough! Use multiple metrics.\n",
    "\n",
    "### 6.1 Calculate All Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_pred_proba, model_name):\n",
    "    \"\"\"Calculate all metrics for a model\"\"\"\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "results = [\n",
    "    evaluate_model(y_test, y_pred_lr, y_pred_proba_lr, 'Logistic Regression'),\n",
    "    evaluate_model(y_test, y_pred_knn, y_pred_proba_knn, 'K-Nearest Neighbors'),\n",
    "    evaluate_model(y_test, y_pred_dt, y_pred_proba_dt, 'Decision Tree'),\n",
    "    evaluate_model(y_test, y_pred_rf, y_pred_proba_rf, 'Random Forest')\n",
    "]\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# QUESTIONS:\n",
    "# 1. Which model has the highest accuracy?\n",
    "# 2. Which model has the highest recall? (important for catching churners)\n",
    "# 3. Is there a model with high precision but low recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Confusion Matrix for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model by ROC-AUC\n",
    "best_model_name = results_df.loc[results_df['ROC-AUC'].idxmax(), 'Model']\n",
    "print(f\"Best Model: {best_model_name}\\n\")\n",
    "\n",
    "# Get predictions for best model (assuming it's Random Forest)\n",
    "y_pred_best = y_pred_rf  # Change if different model is best\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Churn', 'Churn'],\n",
    "            yticklabels=['No Churn', 'Churn'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(\"\\nConfusion Matrix Breakdown:\")\n",
    "print(f\"True Negatives (correctly predicted no churn): {tn}\")\n",
    "print(f\"False Positives (incorrectly predicted churn): {fp}\")\n",
    "print(f\"False Negatives (missed churners): {fn}\")\n",
    "print(f\"True Positives (correctly predicted churn): {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_data = [\n",
    "    ('Logistic Regression', y_pred_proba_lr),\n",
    "    ('K-Nearest Neighbors', y_pred_proba_knn),\n",
    "    ('Decision Tree', y_pred_proba_dt),\n",
    "    ('Random Forest', y_pred_proba_rf)\n",
    "]\n",
    "\n",
    "for name, y_proba in models_data:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Model Comparison')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# QUESTION: What does the area under the ROC curve represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Make Predictions on New Data\n",
    "\n",
    "**Task**: Use the best model to predict churn for new customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample new customers\n",
    "new_customers = pd.DataFrame({\n",
    "    'account_length': [100, 150],\n",
    "    'international_plan': [1, 0],\n",
    "    'voice_mail_plan': [0, 1],\n",
    "    'num_voice_messages': [20, 10],\n",
    "    'total_day_minutes': [200, 150],\n",
    "    'total_day_calls': [100, 80],\n",
    "    'total_eve_minutes': [150, 120],\n",
    "    'total_night_minutes': [100, 90],\n",
    "    'total_intl_calls': [5, 2],\n",
    "    'customer_service_calls': [3, 1]\n",
    "})\n",
    "\n",
    "print(\"New Customers:\")\n",
    "print(new_customers)\n",
    "\n",
    "# Make predictions (use best model - assuming Random Forest)\n",
    "predictions = rf_model.predict(new_customers)\n",
    "probabilities = rf_model.predict_proba(new_customers)\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "for i, (pred, prob) in enumerate(zip(predictions, probabilities)):\n",
    "    print(f\"\\nCustomer {i+1}:\")\n",
    "    print(f\"  Prediction: {'CHURN' if pred == 1 else 'NO CHURN'}\")\n",
    "    print(f\"  Churn Probability: {prob[1]:.1%}\")\n",
    "    print(f\"  Confidence: {'High' if max(prob) > 0.8 else 'Medium' if max(prob) > 0.6 else 'Low'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Reflection Questions\n",
    "\n",
    "Answer these to solidify your understanding:\n",
    "\n",
    "1. **Why did we use train-test split?**\n",
    "   - Answer: [Write your answer]\n",
    "\n",
    "2. **Which metric is most important for churn prediction and why?**\n",
    "   - Answer: [Write your answer]\n",
    "\n",
    "3. **What does a high false negative rate mean for the business?**\n",
    "   - Answer: [Write your answer]\n",
    "\n",
    "4. **When would you choose Logistic Regression over Random Forest?**\n",
    "   - Answer: [Write your answer]\n",
    "\n",
    "5. **How can we improve model performance?**\n",
    "   - Answer: [Write your answer]\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Next Steps\n",
    "\n",
    "1. âœ… Complete all cells in this notebook\n",
    "2. âœ… Try changing hyperparameters (max_depth, n_neighbors, etc.)\n",
    "3. âœ… Experiment with different train-test split ratios\n",
    "4. âœ… Add cross-validation to the evaluation\n",
    "5. âœ… Save the best model using pickle\n",
    "6. âœ… Create a simple Flask API for the model\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ Key Takeaways\n",
    "\n",
    "- Always split data before training\n",
    "- Use multiple metrics, not just accuracy\n",
    "- Understand the confusion matrix\n",
    "- Choose metrics based on business context\n",
    "- Different algorithms have different strengths\n",
    "- Feature scaling matters for some algorithms\n",
    "\n",
    "---\n",
    "\n",
    "**Great job! You've applied all concepts from DataCamp Chapter 1!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
